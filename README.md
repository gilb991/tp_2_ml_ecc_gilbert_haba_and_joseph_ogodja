# Travaux pratiques N¬∞ 2
*Deep learning pour les probl√®mes spatio-temporels : Maintenance pr√©dictive*

par Joseph OGODJA & Gilbert HABA
1. **Objectif**

  L‚Äôobjectif de ce TP est de d√©velopper un mod√®le de pr√©diction bas√© sur des r√©seaux de neurones √†
m√©moire √† long terme (LSTM) afin de pr√©dire l‚Äô√©tat d‚Äôune pompe industrielle en consid√©rant la
composante temporelle.
2. **Description des donn√©es (dataset)**

  Soit le dataset ¬´ maintenance_predictive.csv ¬ª. Ce dataset contient des mesures collect√©es √† partir de capteurs install√©s sur des pompes Industrielles. Il s‚Äôagit d‚Äôun probl√®me de classification multiclasse o√π l‚Äôobjectif est de pr√©dire l‚Äô√©tat de la pompe en fonction des donn√©es temporelles des capteurs. Les classes possibles sont :
  
  - **0** : *Fonctionnement normal.*
  - **1** : *Panne li√©e √† une surchauffe.*
  - **2** : *Panne li√©e √† des vibrations excessives.*
  - **3** : *Panne li√©e √† une surcharge √©lectrique.*

Le dataset contient les colonnes suivantes :
- Variables :
  * **Timestamp** : *Date et heure de la mesure*.
  * **Temperature (¬∞C)** : *Temp√©rature de fonctionnement de la pompe.*
  * **Vibrations (mm/s)** : *Amplitude des vibrations.*
  * **Pressure (bar)** : *Pression exerc√©e par la pompe.*
  * **Current (A)** : *Courant consomm√© par le moteur.*
  * **Operating_Time (heures)** : *Temps de fonctionnement cumul√©.*
  * **Humidity (%)** : *Humidit√© ambiante.*
  * **Noise_Level (dB)** : *Niveau sonore.*
  * **Energy_Consumption (kWh)** : *Consommation √©nerg√©tique.*
  * **Pump_Type** : *Type de pompe (Centrifuge, Diaphragm, Piston).*
  * **Location** : *Localisation de la pompe (Zone A, Zone B, Zone C).*

- Variable cible :
  * **State** : *√âtat de la pompe (0, 1, 2, 3).*



### üìä **Tableau r√©capitulatif des architectures test√©es et performances associ√©es**  

| Mod√®le | Couches principales | Batch Size | Class Weight | Learning Rate | Epochs arr√™t√©es | Train Acc. | Val Acc. | Train Loss | Val Loss | Overfitting ? |
|--------|----------------------|------------|--------------|---------------|-----------------|------------|----------|------------|----------|---------------|
| **V1.0** | LSTM(64) ‚Üí LSTM(32) ‚Üí Dense(32) | 32 | ‚ùå Non | 0.001 | 8 | 30% | ~10% | ‚ÜòÔ∏è Diminue | ‚ÜóÔ∏è Augmente | üî¥ Oui |
| **V2.0** | LSTM(64) ‚Üí LSTM(32) ‚Üí Dense(32) | 32 | ‚ùå Non | 0.001 (avec ReduceLROnPlateau) | 8 | 30% | ~10% | ‚ÜòÔ∏è Diminue | ‚ÜóÔ∏è Augmente | üî¥ Oui |
| **V3.0** | **LSTM(128) ‚Üí LSTM(64) ‚Üí Dense(64)** | **64** | ‚úÖ Oui | 0.001 (avec ReduceLROnPlateau) | 8 | 35% | ~15% | ‚ÜòÔ∏è Diminue | ‚ÜóÔ∏è Augmente | üî¥ Oui |
---

# Entrainement du model 1√®re it√©ration :
D'apr√®s les graphiques de suivi dans **Weights & Biases (WandB)**, voici une analyse d√©taill√©e des performances du mod√®le LSTM :  

---
### **1. √âvolution de la perte sur l‚Äôensemble d'entra√Ænement (`epoch/loss`)**  

![loss](loss.svg)
fig.1 :Courbe d'√©volution de la perte sur l‚Äôensemble d'entra√Ænement

**Interpretations** :

La courbe descend progressivement, ce qui signifie que le mod√®le apprend bien sur les donn√©es d‚Äôentra√Ænement. La perte diminue sans fluctuations majeures. Une perte trop basse pourrait indiquer du surapprentissage (overfitting).  

---

### **2. √âvolution de la perte sur l‚Äôensemble de validation (`epoch/val_loss`)**

![courbe val_loss](val_loss.svg)
fig.2 : Courbe de la perte sur l'ensemble de validation

**Interpretations** :

Contrairement √† la courbe de perte d'entra√Ænement, celle de validation fluctue et **augmente apr√®s un certain nombre d‚Äô√©poques**.  

**Probl√®me possible** :  
- Cela indique un **surapprentissage** (overfitting).  
- Apr√®s un certain nombre d'√©poques, le mod√®le ne g√©n√©ralise plus bien aux nouvelles donn√©es.  

**Solution envisag√©e** :  
- **R√©duire le nombre d‚Äô√©poques** (early stopping).  
- **Ajouter de la r√©gularisation** (Dropout plus √©lev√©, L2).  
- **R√©duire le learning rate progressivement** pour √©viter l‚Äôinstabilit√©.  

---

### **3. Pr√©cision sur l‚Äôensemble d'entra√Ænement (`epoch/accuracy`)**

![accuracy](accuracy.svg)
fig.3 : Courbe de pr√©cision sur l‚Äôensemble d'entra√Ænement 

**Interpretations** :

La courbe est plate et semble s‚Äô√™tre stabilis√©e tr√®s rapidement autour de **0.845** (84.5%). Le mod√®le converge bien. Si elle est **trop haute** par rapport √† `val_accuracy`, cela peut signifier un **overfitting**.  

---

### **4. Pr√©cision sur l‚Äôensemble de validation (`epoch/val_accuracy`)**

![val_accuracy](val_accuracy.svg)
fig.4 : Courbe de pr√©cision sur l‚Äôensemble de validation

**Interpretations** :

La valeur semble **bloqu√©e** et ne progresse pas apr√®s les premi√®res √©poques.  
- Il y a possiblement **une erreur d'affichage** ou **un bug dans le code de logging**.   

---

### **5. Learning Rate (`epoch/learning_rate`)**

![learning_rate](learning_rate.svg)
fig.5 : Courbe de taux d'apprentissage

**Interpretations** :

Il reste constant √† **0.001**, sans ajustement au fil des √©poques.  

# Entrainement du model 2√®me it√©ration :

### Am√©liorations cl√©s :
1. **Correction des erreurs W&B** :  
   - Ajout de `{epoch:02d}` dans le `filepath` pour √©viter l'erreur `FileNotFoundError`
   - `save_best_only=True` fonctionne maintenant car on s'assure que le fichier est bien sauvegard√©

2. **Meilleure r√©gularisation** :
   - Augmentation du `Dropout` pour √©viter l'overfitting

3. **Optimisation du training** :
   - `ReduceLROnPlateau` r√©duit automatiquement le learning rate si `val_loss` stagne
   - `EarlyStopping` arr√™te l'entra√Ænement si `val_loss` ne s'am√©liore pas pendant 10 √©poques
  
### R√©sultats obtenus :

### **1Ô∏è. `epoch/val_loss` (Perte de validation)**
![val_loss_v2](val_loss_v2.svg)
fig.1 : Courbe de la perte sur l'ensemble de validation

**Interpretation :**  
- La courbe est relativement stable jusqu'√† environ **l'√©poque 7**, mais apr√®s, on observe une mont√©e soudaine et une forte variation.  
- Cela indique un **d√©but d'overfitting**, o√π le mod√®le commence √† trop s'adapter aux donn√©es d'entra√Ænement et perd en g√©n√©ralisation.  

---

### **2Ô∏è. `epoch/val_accuracy` (Pr√©cision de validation)**
![val_accuracy_v2](val_accuracy_v2.svg)
fig.2 : Courbe de pr√©cision sur l‚Äôensemble de validation

**Interpretation :**  
- La courbe est **totalement plate**, ce qui est anormal.  
- Il y a un **bug potentiel** o√π l'√©valuation ne se fait pas correctement.  
---

### **3Ô∏è. `epoch/loss` (Perte d'entra√Ænement)**
![loss_v2](loss_v2.svg)
fig.3 :Courbe d'√©volution de la perte sur l‚Äôensemble

**Interpretation :**  
- Le `loss` diminue de fa√ßon r√©guli√®re, ce qui est un bon signe.  
- Pas de signe de divergence ou de forte oscillation, ce qui montre que l'entra√Ænement est bien r√©gl√©. 
---

### **4Ô∏è. `epoch/learning_rate`**
![learning_rate_v2](learning_rate_v2.svg)
fig.4 : Courbe de taux d'apprentissage

**Interpretation :**
- Le `ReduceLROnPlateau` a bien fonctionn√© : le taux d'apprentissage a chut√© apr√®s **l'√©poque 8**, ce qui est une bonne strat√©gie.  
- Cela aurait pu se produire **un peu plus t√¥t** pour √©viter la mont√©e du `val_loss`.
---

### **5Ô∏è. `epoch/accuracy` (Pr√©cision d'entra√Ænement)**
![accuracy_v2](accuracy_v2.svg)
fig.5 : Courbe de pr√©cision sur l‚Äôensemble d'entra√Ænement

**Interpretation :**  
- On atteint rapidement **84.4% de pr√©cision**, puis la courbe devient plate.  
- Cela pourrait √™tre un signe de **plateau de convergence**, mais aussi de **mauvaise gestion des classes** si `val_accuracy` reste fig√© √† 1.
---

# Entrainement du model 3√®me it√©ration :

### Am√©liorations apport√©es :
1. **Augmentation de la capacit√© du mod√®le** :  
   - Plus de neurones dans les couches LSTM pour capturer plus de complexit√©.
  
2. **Correction de la m√©trique `val_accuracy`** :  
   - Remplacement de `accuracy` par `sparse_categorical_accuracy` pour correspondre √† la loss utilis√©e.

3. **Gestion des classes d√©s√©quilibr√©es** :  
   - Calcul de `class_weight` pour que le mod√®le ne soit pas biais√© vers la classe majoritaire.

4. **Optimisation du `learning rate`** :  
   - R√©duction plus rapide du `LR` si `val_loss` stagne.
   - `EarlyStopping` plus agressif pour √©viter un overfitting inutile.

5. **Augmentation du `batch_size`** :  
   - Passage √† `64` pour stabiliser l'entra√Ænement.

### R√©sultats obtenus :
1. **Validation Accuracy (epoch/val_sparse_categorical_accuracy)**
   ![val_sparse_categorical_accuracy_v3](val_sparse_categorical_accuracy.svg)
   
   - La courbe montre une chute brutale apr√®s la premi√®re √©poque, et elle reste proche de z√©ro.  
   - Cela sugg√®re que le mod√®le ne g√©n√©ralise pas bien sur les donn√©es de validation, ce qui peut √™tre d√ª √† un surajustement aux donn√©es d'entra√Ænement ou un probl√®me de distribution des classes.

2. **Validation Loss (epoch/val_loss)**
   ![val_loss_v3](val_loss_v3.svg)

   - La perte de validation augmente progressivement au fil des √©poques, indiquant que le mod√®le devient moins performant sur l'ensemble de validation.  
   - Un tel comportement est un signe d‚Äôoverfitting, o√π le mod√®le apprend trop bien les donn√©es d'entra√Ænement et ne parvient pas √† g√©n√©raliser.

3. **Training Accuracy (epoch/sparse_categorical_accuracy)**
   ![sparse_categorical_accuracy](sparse_categorical_accuracy.svg)

   - La courbe est instable et montre des fluctuations importantes.  
   - Cela peut indiquer que l'entra√Ænement est instable, potentiellement en raison d'un taux d'apprentissage trop √©lev√© ou d'une architecture inadapt√©e.

4. **Training Loss (epoch/loss)**
   ![loss_v3](loss_v3.svg) 

   - La perte d'entra√Ænement diminue progressivement, ce qui montre que le mod√®le apprend bien sur l‚Äôensemble d'entra√Ænement.  
   - Cependant, la divergence avec la perte de validation sugg√®re un overfitting.

5. **Learning Rate (epoch/learning_rate)**  
   ![learning_rate_v3](learning_rate_v3.svg)

   - Le taux d‚Äôapprentissage diminue brusquement apr√®s quelques √©poques.  
   - Bien que cette technique aide souvent √† stabiliser l'entra√Ænement, cela ne semble pas suffisant pour emp√™cher l‚Äôoverfitting.